# InferLite
lightweight inference engine for executing trained neural network models efficiently

goal: learn the infrastructure behind graph optimization, kernel fusion and all under the hood features of an inference engine.

by the end of this project my inference engine should: 

- Load the model
- Construct a graph representation of the model
- Topologically sort nodes
- Run inference with user inputs
